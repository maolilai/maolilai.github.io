---
### 1. HBase的特点是什么？
- HBase是一个分布式、基于列式存储的数据库，基于Hadoop的HDFS存储，ZooKeeper进行管理；
- HBase适合存储半结构化、非结构化的数据，适合存储数据结构字段不够确定、或杂乱无章，很难按照一个概念去抽取的数据；
- HBase中，null不会被存储；
- HBase中的表，由RowKey、时间戳、列簇组成，在写入新数据时，时间戳会更新，同时可以查询到以前的版本；
- HBase是主从结构，HMaster是主节点，HRegionServer是从节点；


---
### 2. HBase如何导入数据？
- 使用MapReduce Job方式，根据HBase API编写Java脚本，将文本文件用文件流的方式截取，然后存储到多个字符串数据中，在put方法下，通过对表中的列簇进行for循环遍历列名，用if判断列名后进行for循环，调用put/ add方法对列簇下每一个列进行设置，每个列簇下有几个就赋值几次，没有表就先创建表；


---
#### 3. HBase的存储结构是什么？
- Hbase中的每张表都通过行键RowKey按照一定的范围，被分割成多个子表HRegion，默认一个HRegion超过256M，就要被分割成两个，由HRegionServer 管理，管理哪些HRegion由Hmaster分配；
- HRegion存取一个子表时，会创建一个HRegion对象，然后对表的每个列簇Column Family创建一个store实例，每个store都会有0或多个StoreFile 与之对应，每个StoreFile都会对应一个HFile，HFile就是实际的存储文件。因此，一个HRegion还拥有一个MemStore实例；


---
### 4. Hbase和hive有什么区别？hive与hbase的底层存储是什么？hive是产生的原因是什么？hbase是为了弥补hadoop的什么缺陷而产生的？
- hbase与hive都是架构在hadoop之上的，都是用HDFS作为底层存储；
- Hive是建立在Hadoop之上，为了减少MapReduce Jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目；
- 想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop；如果是索引访问，就用HBase+Hadoop；
- Hive query就是MapReduce jobs，可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多；
- Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑； 
- hive借用hadoop的MapReduce来完成一些hive中的命令的执行；
- hbase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作；
- hbase是列存储；
- hdfs作为底层存储，hdfs是存放文件的系统，而Hbase负责组织文件；
- hive需要用到hdfs存储文件，需要用到MapReduce计算框架；
Hive和Hbase是两种基于Hadoop的不同技术--Hive是一种类SQL 的引擎，并且运行MapReduce 任务，Hbase 是一种在Hadoop之上的NoSQL的Key/vale数据库。当然，这两种工具是可以同时使用的。就像用Google 来搜索，用FaceBook 进行社交一样，Hive 可以用来进行统计查询，HBase 可以用来进行实时查询，数据也可以从Hive 写到Hbase，设置再从Hbase 写回Hive。
Hive是一个构建在Hadoop 基础之上的数据仓库。通过Hive可以使用HQL语言查询存放在HDFS 上的数据。
HQL是一种类SQL语言，这种语言最终被转化为Map/Reduce. 虽然Hive提供了SQL查询功能，但是Hive 不能够进行交互查询,因为它只能够在Haoop上批量的执行Hadoop。
Hive 被分区为表格，表格又被进一步分割为列簇。列簇必须使用schema 定义，列簇将某一类型列集合起来（列不要求schema定义）。
限制 ：
Hive 目前不支持更新操作。
另外，由于hive在hadoop上运行批量操作，它需要花费很长的时间，通常是几分钟到几个小时才可以获取到查询的结果。
Hive 适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。
Hive 不应该用来进行实时的查询。因为它需要很长时间才可以返回结果。


---
### 5. 解释下hbase实时查询的原理？
- 实时查询，可以认为是从内存中查询，一般响应时间在1秒内。HBase的机制是数据先写入到内存中，当数据量达到一定的量（如128M），再写入磁盘中， 在内存中，是不进行数据的更新或合并操作的，只增加数据，这使得用户的写操作只要进入内存中就可以立即返回，保证了HBase I/O的高性能；


---
### 6. 列簇怎么创建比较好？(<=2)
- RowKey最好要创建有规则的RowKey，即最好是有序的。HBase中一张表最好只创建一到两个列族比较好，因为HBase不能很好的处理多个列族；


---
### 7. 描述Hbase中scan和get的功能以及实现的异同？
- 按指定RowKey获取唯一一条记录，get方法（org.apache.hadoop.hbase.client.Get）处理分两种：设置了ClosestRowBefore和没有设置的rowlock ，主要是用来保证行的事务性，即每个get是以一个row来标记的。一个 row 中可以有很多 family 和 column；
- 按指定的条件获取一批记录， scan 方法(org.apache.Hadoop.hbase.client.Scan)实现条件查询功能使用的就是 scan 方式.1)scan 可以通过 setCaching 与 setBatch 方法提高速度(以空间换时间)； 2)scan 可以通过 setStartRow 与 setEndRow 来限定范围([start， end]start 是闭区间， end 是开区间)。范围越小，性能越高。3)scan 可以通过 setFilter 方法添加过滤器，这也是分页、多条件查询的基础。
- 全表扫描，即直接扫描整张表中所有行记录；


---
### 8. 请详细描述Hbase中一个Cell的结构？
- HBase中通过row和columns确定的为一个存储单元称为cell。Cell：由{row key, column(=<family> + <label>), version}是唯一确定的单元
- cell中的数据是没有类型的，全部是字节码形式存贮 ；


---
### 9. 请描述Hbase中scan对象的setCache和setBatch方法的使用？
- cache：在默认情况下，如果你需要从hbase中查询数据，在获取结果ResultScanner时，hbase会在你每次调用ResultScanner.next（）操作时对返回的每个Row执行一次RPC操作。即使你使用ResultScanner.next(int nbRows)时也只是在客户端循环调用RsultScanner.next()操作，你可以理解为hbase将执行查询请求以迭代器的模式设计，在执行next（）操作时才会真正的执行查询操作，而对每个Row都会执行一次RPC操作。因此显而易见的就会想如果我对多个Row返回查询结果才执行一次RPC调用，那么就会减少实际的通讯开销。这个就是hbase配置属性“hbase.client.scanner.caching”的由来，设置cache可以在hbase配置文件中显示静态的配置，也可以在程序动态的设置。
- cache值得设置并不是越大越好，需要做一个平衡。cache的值越大，则查询的性能就越高，但是与此同时，每一次调用next（）操作都需要花费更长的时间，因为获取的数据更多并且数据量大了传输到客户端需要的时间就越长，一旦你超过了maximum heap the client process 拥有的值，就会报outofmemoryException异常。当传输rows数据到客户端的时候，如果花费时间过长，则会抛出ScannerTimeOutException异常。
- batch：在cache的情况下，我们一般讨论的是相对比较小的row，那么如果一个Row特别大的时候应该怎么处理呢？要知道cache的值增加，那么在client process占用的内存就会随着row的增大而增大。在hbase中同样为解决这种情况提供了类似的操作：Batch。可以这么理解，cache是面向行的优化处理，batch是面向列的优化处理。它用来控制每次调用next（）操作时会返回多少列，比如你设置setBatch（5），那么每一个Result实例就会返回5列，如果你的列数为17的话，那么就会获得四个Result实例，分别含有5,5,5,2个列。
 
下面会以表格的形式来帮助理解，假设我们拥有10Row，每个row拥有2个family，每个family拥有10个列。（也就是说每个Row含有20列）
caching	batch	Results	RPCs	Notes
1	1	200	201	额外的一个RPC是用来判断scan是否完成
200	1	200	2	 
2000	100	10	1	超过的部分没有用处，但是判断scan也在那一个RPC 中完成
2	100	10	6	10/2 +1 (额外的判断开销）
2	10	20	11	 
5	100	10	3	 
5	20	10	3	 
10	10	20	3	 
 
RPCs=(Rows* Cols per Row) / Min(Cols per Row, Batch size) / Scanner caching


---
### 10. 简述 HBASE 中 compact 用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？
- 在 hbase 中每当有 memstore 数据 flush 到磁盘之后，就形成一个 storefile，当 storeFile 的数量达到一定程度后，就需要将 storefile 文件来进行 compaction 操作；
- Compact 的作用：合并文件；清除过期，多余版本的数据；提高读写数据的效率；
- HBase 中实现了两种 compaction 的方式：minor and major. 这两种 compaction 方式的区别是：
- 1、 Minor 操作只用来做部分文件的合并操作以及包括 minVersion=0 并且设置 ttl 的过期版本清理，不做任何删除数据、多版本数据的清理工作。
- 2、 Major 操作是对 Region 下的 HStore 下的所有 StoreFile 执行合并操作，最终的结果是整理合并出一个文件。简述 Hbase filter 的实现原理是什么？结合实际项目经验，写出几个使用 filter 的场景HBase 为筛选数据提供了一组过滤器，通过这个过滤器可以在 HBase 中的数据的多个维度（行，列，数据版本）上进行对数据的筛选操作，也就是说过滤器最终能够筛选的数据能够细化到具体的一个存储单元格上（由行键，列名，时间戳定位）。RowFilter、PrefixFilter。。。hbase的filter是通过scan设置的，所以是基于scan的查询结果进行过滤.过滤器的类型很多，但是可以分为两大类——比较过滤器，专用过滤器过滤器的作用是在服务端判断数据是否满足条件，然后只将满足条件的数据返回给客户端；如在进行订单开发的时候，我们使用RowKeyfilter过滤出某个用户的所有订单


---
### 11. Hbase内部是什么机制？
- 在HBase中无论是增加新行还是修改已有行，其内部流程都是相同的。 HBase 接到命令后存下变化信息，或者写入失败抛出异常。默认情况下，执行写入时会写到两个地方：预写式日志（write-ahead log，也称 HLog）和 MemStore。 HBase 的默认方式是把写入动作记录在这两个地方，以保证数据持久化。只有当这两个地方的变化信息都写入并确认后，才认为写动作完成。MemStore 是内存里的写入缓冲区， HBase 中数据在永久写入硬盘之前在这里累积。当MemStore 填满后，其中的数据会刷写到硬盘，生成一个 HFile。 HFile 是 HBase 使用的底层存储格式。 HFile 对应于列族，一个列族可以有多个 HFile，但一个 HFile 不能存储多个列族的数据。在集群的每个节点上，每个列族有一个 MemStore。大型分布式系统中硬件故障很常见， HBase 也不例外。设想一下，如果 MemStore 还没有刷写，服务器就崩溃了，内存中没有写入硬盘的数据就会丢失。 HBase 的应对办法是在写动作完成之前先写入 WAL。 HBase 集群中每台服务器维护一个 WAL 来记录发生的变化。WAL 是底层文件系统上的一个文件。直到 WAL 新记录成功写入后，写动作才被认为成功完成。这可以保证 HBase 和支撑它的文件系统满足持久性。大多数情况下， HBase 使用Hadoop 分布式文件系统（HDFS）来作为底层文件系统。如果 HBase 服务器宕机，没有从 MemStore 里刷写到 HFile 的数据将可以通过回放WAL 来恢复。你不需要手工执行。 Hbase 的内部机制中有恢复流程部分来处理。每台HBase 服务器有一个 WAL，这台服务器上的所有表（和它们的列族）共享这个 WAL。你可能想到，写入时跳过 WAL 应该会提升写性能。但我们不建议禁用 WAL，除非你愿意在出问题时丢失数据。如果你想测试一下，如下代码可以禁用 WAL： 注意：不写入 WAL 会在 RegionServer 故障时增加丢失数据的风险。关闭 WAL，出现故障时 HBase 可能无法恢复数据，没有刷写到硬盘的所有写入数据都会丢失。 


---
### 12. HBase 宕机如何处理？
- 宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer 上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。如果是 HMaster 宕机， HMaster 没有单点问题， HBase 中可以启动多个 HMaster，通过Zookeeper 的 Master Election 机制保证总有一个 Master 运行。即 ZooKeeper 会保证总会有一个 HMaster 在对外提供服务。


---
### 13. 导致Hbase挂掉的场景
HMaster
HMaster会出现异常(执行abort())停止的场景如下：
1.zk异常导致的master停止服务是最常见的场景，涉及操作包含但不限于以下：
  a)Zk链接超时，超时时间通过zookeeper.session.timeout配置，默认为3分钟, 如果fail.fast.expired.active.master配置的值为false（默认为false），则不会立即abort，而是会尝试恢复zk的过期session；
  b)在打开region后，需要从zk中删除opened节点，如果zk有该节点，但是删除失败；
  c)在split region过程中，从zk删除split节点时；
  d)Master节点改变时；
  e)从zk中创建unassigned节点时；
  f)在下线disabled的regoin时，从zk中删除disabled的region如果发生zk异常；
  g)还有很多操作zk的节点时如果出现异常。
2.在assign时，如果设置region为offlined状态，但是region之前的状态不是closed或者offlined；
3.在assign时，如果无法从.META.表中读取region信息；
4.把新的hbase集群加入到正在运行的hbase集群时，如果zk的/hbase/unassigned节点没有数据；
5.使用线程池批量分配region时，如果出现未被捕获的异常，实现方式如下：
6.在启动master的服务线程时，出现了异常；
7.在hdfs中检查hbase日志路径时，发现了dead的server时，需从hdfs中读出log，如果出现io异常需要检查hdfs文件系统，如果fsOk状态为true，但是通过FSUtils工具类进行检查时出现io异常；
8.在校验并且分配-ROOT-的region时，如果zk异常，或者其它异常（其它异常会重试10次），比如：“-ROOT- is onlined on the dead server”。 

HRegionServer
HRegionServer会出现异常停止(执行abort())服务的场景如下：
1.在读写hdfs时如果出现IOException异常，此时会发起hdfs的文件系统检查（checkFileSystem）1.          
2.Regionserver的服务线程出现了未捕获异常；
3.在启动HRegionServer时出现异常；
4.在进行HLog回滚时，出现异常；
5.在flush memstore时，如果持久化失败，会重启RS，在重启中把hlog的内容重新加载到memstore；
6.出现zk异常，包括但不限于以下场景：
  a)Zk链接超时，超时时间通过zookeeper.session.timeout配置，默认为3分钟，与master不同，如果zk操作不会重试；
  b)启动HRegionServer时出现KeeperException异常； 
  c)在进行split操作时，如果出现异常会进行回滚操作，在回滚过程中需要从zk中删除region的spliting状态，如果删除时出现KeeperException或者回滚的其它操作出现异常；
  d)在打开region时，出现了KeeperException异常；
  e)在进行hbase集群复制时，很多与zk交互的操作出现KeeperException异常时均会导致abort；
7.在close region时，如果出现异常，比如：不能成功的flush memstore；
8.Flush memstore时，如果HLog发现该region已经在flush则会强制终止JVM，采用的是Runtime.getRuntime().halt(1)方法，该方法不会执行正常退出的关闭钩子，从而不会flush RS的所有region，也不会迁移region，只有等待ZK的session超时后master才会发现该RS不可用，做迁移工作。

总结
Hbase挂掉的可能性有很多，主要由zk或者hdfs的问题导致，因此zk、hdfs的可用对于hbase极其重要，关于zk：
1.zk如果停止了服务则在很多时候会导致master、rs挂掉，hbase集群基本上就失去了服务的能力，因此zk一定要是稳定可靠的，当client已经于rs建立了链接，这时zk挂掉，如果不进行split等小数与zk交互失败会导致触发rs的abort()的操作时rs还是可以提供服务的；
2.如果rs/master进行了长时间的gc或者改动了服务器时间，导致出现zk的session超时会导致rs/master停止服务，目前已经出现了2次因为服务器时间变化导致hbase停止服务的事故;
3.别轻易人为改变zk的hbase节点数据，master/rs在进行很多操作时会比较依赖zk的数据，如果发现不符合预期可能会导致master/rs停止服务，尤其是master。
Master通过ZK知道RS是否可用，一般情况下RS在停止服务时均会正常退出，在正常退出时会从ZK中删除/hbase/rs/$regionserver的节点，Master会监听该节点的被删除，从而较快的(速度取决于所有region关闭时间)对该RS负责的region进行重新分配，如果是强制退出，比如 kill -9或者出现HRegionServer挂掉的第8条时则只有等待ZK的session超时时才会删除RS在ZK的节点（RS在ZK中添加节点时采用的是CreateMode.EPHEMERAL模式，该模式创建的节点会在session关闭时自动删除），那时Master才会进行重新assign。
Kill RS的进程也是正常退出（不能使用kill -9强制退出），RS使用Runtime的addShutdownHook方法注册了jvm关闭钩子，在关闭钩子中会执行RS的退出逻辑，实际上hbase-daemon.sh的停止RS就是采用kill


---
### 14. HBase 的特点是什么？

1）大：一个表可以有数十亿行，上百万列；
2）无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一
张表中不同的行可以有截然不同的列；
3）面向列：面向列（族）的存储和权限控制，列（族）独立检索；
4）稀疏：空（null）列并不占用存储空间，表可以设计的非常稀疏；
5）数据多版本：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元
格插入时的时间戳；
6）数据类型单一：Hbase 中的数据都是字符串，没有类型。


---
### 15. HBase适用于怎样的情景？
- 半结构化或非结构化数据
- 记录非常稀疏
- 多版本数据
- 超大数据量


---
### 16. 描述HBase的RowKey的设计原则？
- Rowkey 长度原则。Rowkey 是一个二进制码流，Rowkey 的长度被很多开发者建议说设计在 10~100 个字节，不过建议是越短越好，不要超过 16 个字节。
    - 原因如下：
    -（1）数据的持久化文件 HFile 中是按照 KeyValue 存储的，如果 Rowkey 过长比如 100个字节，1000 万列数据光 Rowkey 就要占用 100*1000 万=10 亿个字节，将近 1G 数据，这会极大影响 HFile 的存储效率；
    -（2）MemStore 将缓存部分数据到内存，如果 Rowkey 字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，这会降低检索效率。因此 Rowkey 的字节长度越短越好。
    -（3）目前操作系统是都是 64 位系统，内存 8 字节对齐。控制在 16 个字节，8 字节的整数倍利用操作系统的最佳特性。
- Rowkey 散列原则。如果Rowkey 是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将Rowkey的高位作为散列字段，由程序循环生成，低位放时间字段，这样将提高数据均衡分布在每个Regionserver 实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息将产生所有新数据都在一个 RegionServer 上堆积的热点现象，这样在做数据检索的时候负载将会集中在个别 RegionServer，降低查询效率。
- Rowkey 唯一原则。必须在设计上保证其唯一性。


---
### 17. HBase 优化？
- （1）高可用。在 HBase 中 Hmaster 负责监控 RegionServer 的生命周期，均衡 RegionServer 的负载，如果 Hmaster 挂掉了，那么整个 HBase 集群将陷入不健康的状态，并且此时的工作状态并不会维持太久。所以 HBase 支持对 Hmaster 的高可用配置。 
- （2）预分区。每一个 region 维护着 startRow 与 endRowKey，如果加入的数据符合某个 region 维护的rowKey 范围，则该数据交给这个 region 维护。那么依照这个原则，我们可以将数据所要投放的分区提前大致的规划好，以提高 HBase 性能 .
- （3）RowKey 设计。一条数据的唯一标识就是 rowkey，那么这条数据存储于哪个分区，取决于 rowkey 处于哪个一个预分区的区间内，设计 rowkey 的主要目的 ，就是让数据均匀的分布于所有的 region中，在一定程度上防止数据倾斜。接下来我们就谈一谈 rowkey 常用的设计方案 
-（4）7.4 内存优化。HBase 操作过程中需要大量的内存开销，毕竟 Table 是可以缓存在内存中的，一般会分配整个可用内存的 70%给 HBase 的 Java 堆。但是不建议分配非常大的堆内存，因为 GC 过程持续太久会导致 RegionServer 处于长期不可用状态，一般 16~48G 内存就可以了，如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。
-（5）基础优化 、


---
### 18. Region 如何预建分区？
- 预分区的目的主要是在创建表的时候指定分区数，提前规划表有多个分区，以及每个分区的区间范围，这样在存储的时候 rowkey 按照分区的区间存储，可以避免 region 热点问题。
通常有两种方案：
- 方案 1:shell 方法。create 'tb_splits', {NAME => 'cf',VERSIONS=> 3},{SPLITS => ['10','20','30']}
- 方案 2: JAVA 程序控制
    - 取样，先随机生成一定数量的 rowkey,将取样数据按升序排序放到一个集合里；
    - 根据预分区的 region 个数，对整个集合平均分割，即是相关的 splitKeys；
    - HBaseAdmin.createTable(HTableDescriptor tableDescriptor,byte[][]splitkeys)可以指定预分区的 splitKey，即是指定 region 间的 rowkey 临界值。 


---
### 19. HBase 读写流程？（☆☆☆☆☆） 
- 读：
① HRegionServer 保存着 meta 表以及表数据，要访问表数据，首先 Client 先去访问zookeeper，从 zookeeper 里面获取 meta 表所在的位置信息，即找到这个 meta 表在哪个HRegionServer 上保存着。
② 接着 Client 通过刚才获取到的 HRegionServer 的 IP 来访问 Meta 表所在的HRegionServer，从而读取到 Meta，进而获取到 Meta 表中存放的元数据。
③ Client 通过元数据中存储的信息，访问对应的 HRegionServer，然后扫描所在HRegionServer 的 Memstore 和 Storefile 来查询数据。
④ 最后 HRegionServer 把查询到的数据响应给 Client。
- 写：
① Client 先访问 zookeeper，找到 Meta 表，并获取 Meta 表元数据。
② 确定当前将要写入的数据所对应的 HRegion 和 HRegionServer 服务器。
③ Client 向该 HRegionServer 服务器发起写入数据请求，然后 HRegionServer 收到请求
并响应。 

④ Client 先把数据写入到 HLog，以防止数据丢失。
⑤ 然后将数据写入到 Memstore。
⑥ 如果 HLog 和 Memstore 均写入成功，则这条数据写入成功
⑦ 如果 Memstore 达到阈值，会把 Memstore 中的数据 flush 到 Storefile 中。
⑧ 当 Storefile 越来越多，会触发 Compact 合并操作，把过多的 Storefile 合并成一个大
的 Storefile。
⑨ 当 Storefile 越来越大，Region 也会越来越大，达到阈值后，会触发 Split 操作，将
Region 一分为二。


---
### 20. HBase内部机制是什么？
- Hbase 是一个能适应联机业务的数据库系统物理存储：hbase 的持久化数据是将数据存储在 HDFS 上。
- 存储管理：一个表是划分为很多 region 的，这些 region 分布式地存放在很多 regionserver上 Region 内部还可以划分为 store，store 内部有 memstore 和 storefile。
- 版本管理：hbase 中的数据更新本质上是不断追加新的版本，通过 compact 操作来做版本间的文件合并 Region 的 split。
- 集群管理：ZooKeeper + HMaster + HRegionServer。


---
### 21. HBase 在进行模型设计时重点在什么地方？一张表中定义多少个 Column Family 最合适？为什么？ 
- Column Family 的个数具体看表的数据，一般来说划分标准是根据数据访问频度，如一张表里有些列访问相对频繁，而另一些列访问很少，这时可以把这张表划分成两个列族，分开存储，提高访问效率。 


---
### 22. 如何提高 HBase 客户端的读写性能？请举例说明（☆☆☆☆☆） 
- 1 开启 bloomfilter 过滤器，开启 bloomfilter 比没开启要快 3、4 倍
- 2 Hbase 对于内存有特别的需求，在硬件允许的情况下配足够多的内存给它
- 3 通过修改 hbase-env.sh 中的export HBASE_HEAPSIZE=3000 #这里默认为 1000m
- 4 增大 RPC 数量。通过修改 hbase-site.xml 中的 hbase.regionserver.handler.count 属性，可以适当的放大RPC 数量，默认值为 10 有点小。 


---
### 23. 直接将时间戳作为行健，在写入单个 region 时候会发生热点问题，为什么呢？（☆☆☆☆☆） 
- region 中的 rowkey 是有序存储，若时间比较集中。就会存储到一个 region 中，这样一个 region 的数据变多，其它的 region 数据很少，加载数据就会很慢，直到 region 分裂，此问题才会得到缓解。 


---
### 16.请描述如何解决 HBase 中 region 太小和 region 太大带来的冲突？ 
- Region 过大会发生多次compaction，将数据读一遍并重写一遍到 hdfs 上，占用io，region过小会造成多次 split，region 会下线，影响访问服务，最佳的解决方法是调整 hbase.hregion.max.filesize 为 256m。 


---
### 17. 解释一下布隆过滤器原理（☆☆☆☆☆）？ 


--- 
### 18. 描述Hbase中scan和get的功能以及实现的异同？
HBase的查询实现只提供两种方式：
1、按指定RowKey 获取唯一一条记录，get方法（org.apache.hadoop.hbase.client.Get）
Get 的方法处理分两种 : 设置了ClosestRowBefore 和没有设置的rowlock .主要是用来保证行的事务性，即每个get 是以一个row 来标记的.一个row中可以有很多family 和column.
2、按指定的条件获取一批记录，scan方法(org.apache.Hadoop.hbase.client.Scan）实现条件查询功能使用的就是scan 方式.
1)scan 可以通过setCaching 与setBatch 方法提高速度(以空间换时间)；
2)scan 可以通过setStartRow 与setEndRow 来限定范围([start，end)start 是闭区间，
end 是开区间)。范围越小，性能越高。
3)、scan 可以通过setFilter 方法添加过滤器，这也是分页、多条件查询的基础。
 

---
### 19. 请详细描述Hbase中一个Cell 的结构
HBase 中通过row 和columns 确定的为一个存贮单元称为cell。
Cell：由{row key, column(=<family> + <label>), version}唯一确定的单元。cell 中的数
据是没有类型的，全部是字节码形式存贮。
 
 
---
### 20. 请描述如何解决Hbase中region太小和region太大带来的冲突.
- Region过大会发生多次compaction，将数据读一遍并重写一遍到hdfs 上，占用io，region过小会造成多次split，region 会下线，影响访问服务，调整hbase.hregion.max.filesize 为256m.


---
### 21. 以 start-hbase.sh 为起点，Hbase 启动的流程是什么？
start-hbase.sh 的流程如下：
1.运行 hbase-config.sh
hbase-config.sh的作用：
1>.装载相关配置，如HBASE_HOME目录，conf目录，regionserver机器列表，JAVA_HOME 目录等，它会调用$HBASE_HOME/conf/hbase-env.sh .
2>.解析参数（0.96 版本及以后才可以带唯一参数 autorestart，作用就是重启）
3>.调用 hbase-daemon.sh 来启动 master.
4>.调用 hbase-daemons.sh 来启动 regionserver zookeeper master-backup.
2.hbase-env.sh 的作用：
主要是配置 JVM 及其 GC 参数，还可以配置 log 目录及参数，配置是否需要 hbase 管
理 ZK，配置进程 id 目录等.
3.hbase-daemons.sh 的作用：根据需要启动的进程，
如 zookeeper,则调用 zookeepers.sh
如 regionserver，则调用 regionservers.sh
如 master-backup，则调用 master-backup.sh
4.zookeepers.sh 的作用：
如果 hbase-env.sh 中的 HBASE_MANAGES_ZK"="true"，那么通过ZKServerTool这个类解析xml配置文件，获取 ZK 节点列表，然后通过 SSH 向这些节点发送远程命令执行。
5.regionservers.sh 的作用：
与 zookeepers.sh 类似，通过配置文件，获取 regionserver 机器列表，然后 SSH 向这些机器发送远程命令：
6.master-backup.sh 的作用：
通过 backup-masters 这个配置文件，获取 backup-masters 机器列表,然后 SSH 向这些机器发送远程命令。
 

---
### 22. 简述 HBASE中compact用途是什么，什么时候触发，分为哪两种,有什么区别，有哪些相关配置参数？
在hbase中每当有memstore数据flush到磁盘之后，就形成一个storefile，当storeFile的数量达到一定程度后，就需要将 storefile 文件来进行 compaction 操作。
Compact 的作用？
1>.合并文件
2>.清除过期，多余版本的数据
3>.提高读写数据的效率
HBase 中实现了两种 compaction 的方式：minor and major. 这两种 compaction 方式的区别是：
1、Minor 操作只用来做部分文件的合并操作以及包括 minVersion=0 并且设置 ttl 的过
期版本清理，不做任何删除数据、多版本数据的清理工作。
2、Major 操作是对 Region 下的HStore下的所有StoreFile执行合并操作，最终的结果是整理合并出一个文件。
 
相关配置举例：
 

---
### 23. Hbase热点(数据倾斜)问题 读写请求会集中到某一个RegionServer上 如何处理


---
### 24. Hbase的原理 regionserver挂了 如何恢复数据 ？新的数据从Hlog里读出来是如何恢复的
引起RegionServer宕机的原因各种各样，有因为Full GC导致、网络异常导致、官方Bug导致（close wait端口未关闭）以及DataNode异常导致等等
HBase检测宕机是通过Zookeeper实现的， 正常情况下RegionServer会周期性向Zookeeper发送心跳，一旦发生宕机，心跳就会停止，超过一定时间（SessionTimeout）Zookeeper就会认为RegionServer宕机离线，并将该消息通知给Master
一旦RegionServer发生宕机，HBase都会马上检测到这种宕机，并且在检测到宕机之后会将宕机RegionServer上的所有Region重新分配到集群中其他正常RegionServer上去，再根据HLog进行丢失数据恢复，恢复完成之后就可以对外提供服务，整个过程都是自动完成的，并不需要人工介入.


---
### 25. 讲一下Hbase，Hbase二级索引用过吗
默认情况下，Hbase只支持rowkey的查询，对于多条件的组合查询的应用场景，不够给力。
如果将多条件组合查询的字段都拼接在RowKey中显然又不太可能
全表扫描再结合过滤器筛选出目标数据(太低效)，所以通过设计HBase的二级索引来解决这个问题。
这里所谓的二级索引其实就是创建新的表，并建立各列值（family：column）与行键（rowkey）之间的映射关系。这种方式需要额外的存储空间，属于一种以空间换时间的方式


---
### 26. Hbase如何优化的
内存优化
Ø 垃圾回收优化:CMS, G1(Region）
Ø JVM启动：-Xms(1/64) –Xmx(1/4)
Region优化
Ø 预分区
Ø 禁用major合并，手动合并
客户端优化
批处理
Hbase配置优化：参考课件
HDFS优化：参考课件


---
### 27. hbase中查询表名为test，rowkey为userl开头的


---
### 28. hbase表的设计有哪些注意点


---
### 29. HBase与mysql得区别


---
### 30. Hbase有put方法，那如何批量put数据进hbase里，用什么方法


---
### 31. HBase 数据存储，客户需要存储三个字段的数据（ID：：VALUE：：TIMESTAMP），为了满足统计需求，客户希望将100万个测试点的数据在Hbase中存储，每个测试点一年中每五分钟的数据作为一行存储，请确认这要定义存储格式是否合理，请给出最佳的解决方案

























